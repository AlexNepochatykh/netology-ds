{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 по теме Обработка естественного языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bz2\n",
    "import regex\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201030it [01:10, 2837.81it/s]\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "with bz2.BZ2File('data/banki_responses.json.bz2', 'r') as thefile:\n",
    "    for row in tqdm(thefile):\n",
    "        resp = json.loads(row)\n",
    "        if not resp['rating_not_checked'] and (len(resp['text'].split()) > 0):\n",
    "            responses.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Домашнее задание по NLP # 1 [100 баллов]\n",
    "## Классификация по тональности \n",
    "\n",
    "В этом домашнем задании вам предстоит классифицировать по тональности отзывы на банки с сайта banki.ru. [Ссылка на данные](https://drive.google.com/open?id=1CPKtX5HcgGWRpzbWZ2fMCyqgHGgk21l2).\n",
    "\n",
    "Данные содержат непосредственно тексты отзывов, некоторую дополнительную информацию, а также оценку по шкале от 1 до 5. \n",
    "\n",
    "Тексты хранятся в json-ах в массиве responses.\n",
    "\n",
    "Посмотрим на пример отзыва:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'г. Саратов',\n",
       " 'rating_not_checked': False,\n",
       " 'title': 'Карта ко вкладу',\n",
       " 'num_comments': 0,\n",
       " 'bank_license': 'лицензия № 880',\n",
       " 'author': 'ronnichka',\n",
       " 'bank_name': 'Югра',\n",
       " 'datetime': '2015-06-03 20:56:57',\n",
       " 'text': 'Здравствуйте! Хотела написать, что мне месяц не выдают карту ко вкладу, ссылаясь на \"нам же их из Самары везут\" (на секундочку 5 часов езды от нашего города). Но! Прочитала, что людям 3,5 месяцев не выдают карту, и поняла, что у меня все хорошо, пока что. И подарок мне дали, и кулер в отделении есть. Так что я, конечно, готова ждать. Правда хотелось бы не очень долго.',\n",
       " 'rating_grade': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Анализ текстов [40/100]\n",
    "\n",
    "1. Посчитайте количество отзывов в разных городах и на разные банки\n",
    "2. Постройте гистограмы длин слов в символах и в словах (не обязательно)\n",
    "3. Найдите 10 самых частых:\n",
    "    * слов\n",
    "    * слов без стоп-слов\n",
    "    * лемм \n",
    "* существительных\n",
    "4. Постройте кривую Ципфа\n",
    "5. Ответьте на следующие вопросы:\n",
    "    * какое слово встречается чаще, \"сотрудник\" или \"клиент\"?\n",
    "    * сколько раз встречается слова \"мошенничество\" и \"доверие\"?\n",
    "6. В поле \"rating_grade\" записана оценка отзыва по шкале от 1 до 5. Используйте меру $tf-idf$, для того, чтобы найти ключевые слова и биграмы для положительных отзывов (с оценкой 5) и отрицательных отзывов (с оценкой 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Посчитайте количество отзывов в разных городах и на разные банки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bank_name.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.city.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Постройте гистограмы длин слов в символах и в словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"[А-Яа-я]+\")\n",
    "def words_only_list(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text)\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_2'] = df.text.str.lower()\n",
    "df['text_2'] = df.text_2.apply(words_only_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total_word_list = []\n",
    "for i in df.text_2:\n",
    "    total_word_list.extend(i)\n",
    "total_word_array = np.array(list(map(len, total_word_list)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(total_word_list, bins=20, range=(1,20));\n",
    "plt.figure()\n",
    "plt.title('Гистограмма символов в словах')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Найдите 10 самых частых: * слов * слов без стоп-слов * лемм * существительных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for index, row in tqdm(df.iterrows(), total = len(df)):\n",
    "    tokens = list(map(words_only_list, [row['text'].lower()]))[0]\n",
    "    cnt.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Тематическое моделирование [20/100]\n",
    "\n",
    "1. Постройте несколько тематических моделей коллекции документов с разным числом тем. Приведите примеры понятных (интерпретируемых) тем.\n",
    "2. Найдите темы, в которых упомянуты конкретные банки (Сбербанк, ВТБ, другой банк). Можете ли вы их прокомментировать / объяснить?\n",
    "\n",
    "Эта часть задания может быть сделана с использованием gensim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Классификация текстов [40/100]\n",
    "\n",
    "Сформулируем для простоты задачу бинарной классификации: будем классифицировать на два класса, то есть, различать резко отрицательные отзывы (с оценкой 1) и положительные отзывы (с оценкой 5). \n",
    "\n",
    "1.  Составьте обучающее и тестовое множество: выберите из всего набора данных N1 отзывов с оценкой 1 и N2 отзывов с оценкой 5 (значение N1 и N2 – на ваше усмотрение). Используйте ```sklearn.model_selection.train_test_split``` для разделения множества отобранных документов на обучающее и тестовое. \n",
    "2. Используйте любой известный вам алгоритм классификации текстов для решения задачи и получите baseline. Сравните разные варианты векторизации текста: использование только униграм, пар или троек слов или с использованием символьных $n$-грам. \n",
    "3. Сравните, как изменяется качество решения задачи при использовании скрытых тем в качестве признаков:\n",
    "    * 1-ый вариант: $tf-idf$ преобразование (```sklearn.feature_extraction.text.TfidfTransformer```) и сингулярное разложение (оно же – латентый семантический анализ) (```sklearn.decomposition.TruncatedSVD```), \n",
    "    * 2-ой вариант: тематические модели LDA (```sklearn.decomposition.LatentDirichletAllocation```). \n",
    "\n",
    "\n",
    "Используйте accuracy и F-measure для оценки качества классификации. \n",
    "\n",
    "Ниже написан примерный Pipeline для классификации текстов. \n",
    "\n",
    "Эта часть задания может быть сделана с использованием sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# !!! На каждом этапе Pipeline нужно указать свои параметры\n",
    "# 1-ый вариант: tf-idf + LSI\n",
    "# 2-ой вариант: LDA\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('vect', CountVectorizer(analyzer = 'char', ngram_range={4,6})),\n",
    "#     ('clf', RandomForestClassifier()),\n",
    "# ])\n",
    "\n",
    "\n",
    "clf = Pipeline([ \n",
    "    ('vect', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('tm', TruncatedSVD()), \n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус [20]\n",
    "\n",
    "Используйте для классификации эмбеддинги слов. Улучшилось ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
